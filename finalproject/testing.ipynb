{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path, matplotlib\n",
    "import matplotlib.pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, center=True):\n",
    "    '''\n",
    "    centers and splits the data for testing and training\n",
    "    returns x_train, x_test, y_train, y_test\n",
    "    '''\n",
    "    label = data.label\n",
    "    df = data.drop(['label','filename'], axis=1)\n",
    "    if center:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df)\n",
    "        df = scaler.transform(df)\n",
    "    return train_test_split(df, label, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(classifier, params, x_train, y_train, name=\"Test_\"):\n",
    "    '''\n",
    "    Uses GridSearchCV to tune hyperparameters and saves the GridSearchCV results\n",
    "    Trains the classifier with the best parameters and scores the model\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "    clf = GridSearchCV(classifier, params, n_jobs=-1, cv=10)\n",
    "    grid = clf.fit(x_train, y_train)\n",
    "    print(\"GridSearchCV elapsed time: {}\".format(time.time() - start_time))\n",
    "\n",
    "    # best_params = grid.best_params_\n",
    "    # best_score = grid.best_score_\n",
    "    # print(\"{}GridSearch \\nBest params: {} \\nScore: {}\".format(name, best_params, best_score))\n",
    "    \n",
    "    # Saves GridSearch Result\n",
    "    filename = \"{}GridSearch.sav\".format(name)\n",
    "    pickle.dump(grid, open(filename, 'wb'))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc(data, center=True):\n",
    "    '''\n",
    "    Uses GridSearchCV to tune hyperparameters for RandomForestClassification\n",
    "    Saves the grid results to a pickle\n",
    "    '''\n",
    "    x_train, x_test, y_train, y_test = preprocess_data(data)\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 5)]\n",
    "    max_depth = [int(x) for x in np.linspace(start = 10, stop = 500, num = 5)]\n",
    "    max_features = ['sqrt','log2', None]\n",
    "    params = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth,\n",
    "        'max_features': max_features,\n",
    "    }\n",
    "    grid = gridsearch(RandomForestClassifier(), params, x_train, y_train, name=\"RandomForest_\")\n",
    "    return grid, x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_grid = rfc(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_linear_svm(data, center=True):\n",
    "    x_train, x_test, y_train, y_test = preprocess_data(data)\n",
    "    C = np.logspace(-2, 4, 7)\n",
    "    gamma = np.logspace(-3, 3, 7)\n",
    "    kernel = ['poly', 'rbf', 'sigmoid']\n",
    "    params = {\n",
    "        'C': C,\n",
    "        'gamma': gamma,\n",
    "        'kernel': kernel,\n",
    "    }\n",
    "    grid = gridsearch(SVC(), params, x_train, y_train, name=\"NonLinearSVC_\")\n",
    "    return grid, x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV elapsed time: 4.502078056335449\n"
     ]
    }
   ],
   "source": [
    "svm_grid, x_train, x_test, y_train, y_test = non_linear_svm(data)\n",
    "svm_res = svm_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_grid = pickle.load(open('RandomForest_GridSearch.sav', 'rb'))\n",
    "svm_grid = pickle.load(open('NonLinearSVC_GridSearch.sav', 'rb'))\n",
    "rfc_res = rfc_grid.cv_results_\n",
    "svm_res = svm_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = svm_grid.best_estimator_\n",
    "scores = cross_val_score(svm_clf, x_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 degrees of freedome 95% two tailed CI\n",
    "t = 2.262\n",
    "mean = np.mean(scores)\n",
    "se = np.std(scores)/10\n",
    "ci = [mean - (t*se), mean + (t*se)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [0.5745889293401935, 0.6134110706598065]\n"
     ]
    }
   ],
   "source": [
    "print(\"95% Confidence Interval: [{}, {}]\".format(ci[0], ci[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58, 0.62, 0.62, 0.64, 0.64, 0.42, 0.76, 0.6 , 0.5 , 0.56, 0.58,\n",
       "       0.62, 0.62, 0.64, 0.64, 0.42, 0.76, 0.6 , 0.5 , 0.56])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((scores, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci(scores):\n",
    "    '''\n",
    "    19 degrees of freedome 95% two tailed CI\n",
    "    '''\n",
    "    t = 2.093\n",
    "    mean = np.mean(scores)\n",
    "    se = np.std(scores)/len(scores)\n",
    "    ci = [mean - (t*se), mean + (t*se)]\n",
    "    print(\"95% Confidence Interval: [{}, {}]\".format(ci[0], ci[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [0.5962719059880272, 0.607728094011973]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = preprocess_data(data)\n",
    "grid = pickle.load(open('RandomForest0_GridSearch.sav', 'rb'))\n",
    "res = grid.cv_results_\n",
    "clf = grid.best_estimator_\n",
    "scores = cross_val_score(clf, x_test, y_test, cv=10)\n",
    "\n",
    "grid = pickle.load(open('RandomForest0_GridSearch.sav', 'rb'))\n",
    "res = grid.cv_results_\n",
    "clf = grid.best_estimator_\n",
    "scores = np.concatenate((scores, cross_val_score(clf, x_train, y_train, cv=10)))\n",
    "get_ci(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   filename            1000 non-null   object \n",
      " 1   tempo               1000 non-null   float64\n",
      " 2   beats               1000 non-null   int64  \n",
      " 3   chroma_stft         1000 non-null   float64\n",
      " 4   rmse                1000 non-null   float64\n",
      " 5   spectral_centroid   1000 non-null   float64\n",
      " 6   spectral_bandwidth  1000 non-null   float64\n",
      " 7   rolloff             1000 non-null   float64\n",
      " 8   zero_crossing_rate  1000 non-null   float64\n",
      " 9   mfcc1               1000 non-null   float64\n",
      " 10  mfcc2               1000 non-null   float64\n",
      " 11  mfcc3               1000 non-null   float64\n",
      " 12  mfcc4               1000 non-null   float64\n",
      " 13  mfcc5               1000 non-null   float64\n",
      " 14  mfcc6               1000 non-null   float64\n",
      " 15  mfcc7               1000 non-null   float64\n",
      " 16  mfcc8               1000 non-null   float64\n",
      " 17  mfcc9               1000 non-null   float64\n",
      " 18  mfcc10              1000 non-null   float64\n",
      " 19  mfcc11              1000 non-null   float64\n",
      " 20  mfcc12              1000 non-null   float64\n",
      " 21  mfcc13              1000 non-null   float64\n",
      " 22  mfcc14              1000 non-null   float64\n",
      " 23  mfcc15              1000 non-null   float64\n",
      " 24  mfcc16              1000 non-null   float64\n",
      " 25  mfcc17              1000 non-null   float64\n",
      " 26  mfcc18              1000 non-null   float64\n",
      " 27  mfcc19              1000 non-null   float64\n",
      " 28  mfcc20              1000 non-null   float64\n",
      " 29  label               1000 non-null   object \n",
      "dtypes: float64(27), int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "0.998\n",
      "test\n",
      "0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bojunyang/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:568: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = preprocess_data(data)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,10,10),learning_rate_init=0.001, max_iter=3000)\n",
    "mlp.fit(x_train, y_train)\n",
    "print(\"train\")\n",
    "print(mlp.score(x_train, y_train))\n",
    "print(\"test\")\n",
    "print(mlp.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
